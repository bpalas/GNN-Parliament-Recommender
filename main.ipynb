{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "enriquecido_df = pd.read_csv('gnn_recommender.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcional \n",
    "enriquecido_df = enriquecido_df.sample(frac=0.7, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Extraer la información de nodos (parlamentarios)\n",
    "# Nos quedamos con las columnas relevantes para los parlamentarios (person_1 y person_2 con sus descripciones)\n",
    "nodos_1 = enriquecido_df[['parliamentarian_1', 'biografia_1', 'region_1', 'partido_1', 'sector_1', 'fuente_1' , 'url_imagen_1']]\n",
    "nodos_2 = enriquecido_df[['parliamentarian_2', 'biografia_2', 'region_2', 'partido_2', 'sector_2', 'fuente_2', 'url_imagen_2']]\n",
    "\n",
    "# Renombrar las columnas de nodos_2 para que coincidan con nodos_1\n",
    "nodos_2.columns = ['parliamentarian_1', 'biografia_1', 'region_1', 'partido_1', 'sector_1', 'fuente_1', 'url_imagen_1']\n",
    "\n",
    "# Concatenar los nodos de ambos parlamentarios (quitar duplicados)\n",
    "nodos = pd.concat([nodos_1, nodos_2], axis=0).drop_duplicates(subset='parliamentarian_1').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 2. Extraer la información de aristas (interacciones)\n",
    "# Nos quedamos con las columnas relevantes para las interacciones entre parlamentarios\n",
    "aristas = enriquecido_df[['parliamentarian_1', 'parliamentarian_2', 'proportion_agreement', 'region_1', 'region_2', 'partido_1', 'partido_2', 'sector_1', 'sector_2']]\n",
    "aristas = aristas.drop_duplicates(subset=['parliamentarian_1', 'parliamentarian_2']).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739ebd3318f44b5b87c60e822a18038d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 2.8556, Train: 1.5373, Val: 1.5363\n",
      "Epoch: 002, Loss: 2.3632, Train: 1.1228, Val: 1.1403\n",
      "Epoch: 003, Loss: 1.2608, Train: 0.3849, Val: 0.4316\n",
      "Epoch: 004, Loss: 0.1481, Train: 1.3926, Val: 1.2960\n",
      "Epoch: 005, Loss: 1.9392, Train: 0.6852, Val: 0.6339\n",
      "Epoch: 006, Loss: 0.4695, Train: 0.3680, Val: 0.4119\n",
      "Epoch: 007, Loss: 0.1354, Train: 0.6910, Val: 0.7271\n",
      "Epoch: 008, Loss: 0.4775, Train: 0.8616, Val: 0.8900\n",
      "Epoch: 009, Loss: 0.7424, Train: 0.8992, Val: 0.9260\n",
      "Epoch: 010, Loss: 0.8085, Train: 0.8410, Val: 0.8704\n",
      "Epoch: 011, Loss: 0.7074, Train: 0.7044, Val: 0.7402\n",
      "Epoch: 012, Loss: 0.4962, Train: 0.5045, Val: 0.5488\n",
      "Epoch: 013, Loss: 0.2545, Train: 0.3340, Val: 0.3694\n",
      "Epoch: 014, Loss: 0.1116, Train: 0.4476, Val: 0.4251\n",
      "Epoch: 015, Loss: 0.2003, Train: 0.6275, Val: 0.5780\n",
      "Epoch: 016, Loss: 0.3938, Train: 0.6074, Val: 0.5598\n",
      "Epoch: 017, Loss: 0.3689, Train: 0.4438, Val: 0.4206\n",
      "Epoch: 018, Loss: 0.1969, Train: 0.3292, Val: 0.3498\n",
      "Epoch: 019, Loss: 0.1084, Train: 0.3788, Val: 0.4203\n",
      "Epoch: 020, Loss: 0.1435, Train: 0.4687, Val: 0.5104\n",
      "Epoch: 021, Loss: 0.2196, Train: 0.5153, Val: 0.5554\n",
      "Epoch: 022, Loss: 0.2656, Train: 0.5061, Val: 0.5460\n",
      "Epoch: 023, Loss: 0.2561, Train: 0.4493, Val: 0.4902\n",
      "Epoch: 024, Loss: 0.2019, Train: 0.3708, Val: 0.4096\n",
      "Epoch: 025, Loss: 0.1375, Train: 0.3259, Val: 0.3498\n",
      "Epoch: 026, Loss: 0.1062, Train: 0.3610, Val: 0.3578\n",
      "Epoch: 027, Loss: 0.1303, Train: 0.4220, Val: 0.4008\n",
      "Epoch: 028, Loss: 0.1781, Train: 0.4346, Val: 0.4106\n",
      "Epoch: 029, Loss: 0.1889, Train: 0.3901, Val: 0.3766\n",
      "Epoch: 030, Loss: 0.1522, Train: 0.3372, Val: 0.3443\n",
      "Epoch: 031, Loss: 0.1137, Train: 0.3271, Val: 0.3534\n",
      "Epoch: 032, Loss: 0.1070, Train: 0.3543, Val: 0.3893\n",
      "Epoch: 033, Loss: 0.1255, Train: 0.3813, Val: 0.4185\n",
      "Epoch: 034, Loss: 0.1454, Train: 0.3868, Val: 0.4241\n",
      "Epoch: 035, Loss: 0.1496, Train: 0.3693, Val: 0.4054\n",
      "Epoch: 036, Loss: 0.1364, Train: 0.3413, Val: 0.3732\n",
      "Epoch: 037, Loss: 0.1165, Train: 0.3242, Val: 0.3464\n",
      "Epoch: 038, Loss: 0.1051, Train: 0.3317, Val: 0.3403\n",
      "Epoch: 039, Loss: 0.1100, Train: 0.3513, Val: 0.3492\n",
      "Epoch: 040, Loss: 0.1234, Train: 0.3589, Val: 0.3537\n",
      "Epoch: 041, Loss: 0.1288, Train: 0.3470, Val: 0.3465\n",
      "Epoch: 042, Loss: 0.1204, Train: 0.3293, Val: 0.3389\n",
      "Epoch: 043, Loss: 0.1084, Train: 0.3231, Val: 0.3434\n",
      "Epoch: 044, Loss: 0.1044, Train: 0.3304, Val: 0.3578\n",
      "Epoch: 045, Loss: 0.1091, Train: 0.3400, Val: 0.3706\n",
      "Epoch: 046, Loss: 0.1156, Train: 0.3423, Val: 0.3733\n",
      "Epoch: 047, Loss: 0.1172, Train: 0.3358, Val: 0.3650\n",
      "Epoch: 048, Loss: 0.1128, Train: 0.3264, Val: 0.3513\n",
      "Epoch: 049, Loss: 0.1065, Train: 0.3223, Val: 0.3405\n",
      "Epoch: 050, Loss: 0.1038, Train: 0.3261, Val: 0.3371\n",
      "Epoch: 051, Loss: 0.1064, Train: 0.3321, Val: 0.3382\n",
      "Epoch: 052, Loss: 0.1103, Train: 0.3327, Val: 0.3383\n",
      "Epoch: 053, Loss: 0.1107, Train: 0.3276, Val: 0.3367\n",
      "Epoch: 054, Loss: 0.1073, Train: 0.3225, Val: 0.3374\n",
      "Epoch: 055, Loss: 0.1040, Train: 0.3222, Val: 0.3426\n",
      "Epoch: 056, Loss: 0.1038, Train: 0.3253, Val: 0.3494\n",
      "Epoch: 057, Loss: 0.1059, Train: 0.3277, Val: 0.3532\n",
      "Epoch: 058, Loss: 0.1074, Train: 0.3268, Val: 0.3517\n",
      "Epoch: 059, Loss: 0.1068, Train: 0.3235, Val: 0.3461\n",
      "Epoch: 060, Loss: 0.1047, Train: 0.3212, Val: 0.3400\n",
      "Epoch: 061, Loss: 0.1032, Train: 0.3218, Val: 0.3363\n",
      "Epoch: 062, Loss: 0.1036, Train: 0.3238, Val: 0.3352\n",
      "Epoch: 063, Loss: 0.1049, Train: 0.3245, Val: 0.3350\n",
      "Epoch: 064, Loss: 0.1053, Train: 0.3230, Val: 0.3350\n",
      "Epoch: 065, Loss: 0.1043, Train: 0.3211, Val: 0.3362\n",
      "Epoch: 066, Loss: 0.1031, Train: 0.3207, Val: 0.3390\n",
      "Epoch: 067, Loss: 0.1028, Train: 0.3217, Val: 0.3424\n",
      "Epoch: 068, Loss: 0.1035, Train: 0.3225, Val: 0.3442\n",
      "Epoch: 069, Loss: 0.1040, Train: 0.3221, Val: 0.3434\n",
      "Epoch: 070, Loss: 0.1037, Train: 0.3209, Val: 0.3405\n",
      "Epoch: 071, Loss: 0.1030, Train: 0.3201, Val: 0.3374\n",
      "Epoch: 072, Loss: 0.1025, Train: 0.3204, Val: 0.3352\n",
      "Epoch: 073, Loss: 0.1027, Train: 0.3211, Val: 0.3343\n",
      "Epoch: 074, Loss: 0.1031, Train: 0.3211, Val: 0.3341\n",
      "Epoch: 075, Loss: 0.1031, Train: 0.3204, Val: 0.3345\n",
      "Epoch: 076, Loss: 0.1026, Train: 0.3198, Val: 0.3358\n",
      "Epoch: 077, Loss: 0.1022, Train: 0.3198, Val: 0.3376\n",
      "Epoch: 078, Loss: 0.1023, Train: 0.3201, Val: 0.3391\n",
      "Epoch: 079, Loss: 0.1025, Train: 0.3202, Val: 0.3394\n",
      "Epoch: 080, Loss: 0.1025, Train: 0.3198, Val: 0.3384\n",
      "Epoch: 081, Loss: 0.1023, Train: 0.3194, Val: 0.3366\n",
      "Epoch: 082, Loss: 0.1020, Train: 0.3193, Val: 0.3350\n",
      "Epoch: 083, Loss: 0.1019, Train: 0.3195, Val: 0.3339\n",
      "Epoch: 084, Loss: 0.1021, Train: 0.3195, Val: 0.3335\n",
      "Epoch: 085, Loss: 0.1021, Train: 0.3193, Val: 0.3337\n",
      "Epoch: 086, Loss: 0.1020, Train: 0.3190, Val: 0.3344\n",
      "Epoch: 087, Loss: 0.1018, Train: 0.3189, Val: 0.3354\n",
      "Epoch: 088, Loss: 0.1017, Train: 0.3190, Val: 0.3363\n",
      "Epoch: 089, Loss: 0.1017, Train: 0.3190, Val: 0.3365\n",
      "Epoch: 090, Loss: 0.1017, Train: 0.3188, Val: 0.3360\n",
      "Epoch: 091, Loss: 0.1016, Train: 0.3186, Val: 0.3350\n",
      "Epoch: 092, Loss: 0.1015, Train: 0.3185, Val: 0.3340\n",
      "Epoch: 093, Loss: 0.1014, Train: 0.3185, Val: 0.3332\n",
      "Epoch: 094, Loss: 0.1015, Train: 0.3185, Val: 0.3329\n",
      "Epoch: 095, Loss: 0.1015, Train: 0.3184, Val: 0.3330\n",
      "Epoch: 096, Loss: 0.1014, Train: 0.3182, Val: 0.3334\n",
      "Epoch: 097, Loss: 0.1013, Train: 0.3182, Val: 0.3340\n",
      "Epoch: 098, Loss: 0.1012, Train: 0.3181, Val: 0.3344\n",
      "Epoch: 099, Loss: 0.1012, Train: 0.3181, Val: 0.3345\n",
      "Epoch: 100, Loss: 0.1012, Train: 0.3180, Val: 0.3341\n",
      "Epoch: 101, Loss: 0.1011, Train: 0.3179, Val: 0.3335\n",
      "Epoch: 102, Loss: 0.1011, Train: 0.3178, Val: 0.3328\n",
      "Epoch: 103, Loss: 0.1010, Train: 0.3178, Val: 0.3323\n",
      "Epoch: 104, Loss: 0.1010, Train: 0.3177, Val: 0.3322\n",
      "Epoch: 105, Loss: 0.1010, Train: 0.3177, Val: 0.3322\n",
      "Epoch: 106, Loss: 0.1009, Train: 0.3176, Val: 0.3325\n",
      "Epoch: 107, Loss: 0.1008, Train: 0.3175, Val: 0.3328\n",
      "Epoch: 108, Loss: 0.1008, Train: 0.3175, Val: 0.3330\n",
      "Epoch: 109, Loss: 0.1008, Train: 0.3174, Val: 0.3329\n",
      "Epoch: 110, Loss: 0.1007, Train: 0.3173, Val: 0.3325\n",
      "Epoch: 111, Loss: 0.1007, Train: 0.3173, Val: 0.3321\n",
      "Epoch: 112, Loss: 0.1007, Train: 0.3172, Val: 0.3317\n",
      "Epoch: 113, Loss: 0.1006, Train: 0.3172, Val: 0.3314\n",
      "Epoch: 114, Loss: 0.1006, Train: 0.3171, Val: 0.3314\n",
      "Epoch: 115, Loss: 0.1006, Train: 0.3170, Val: 0.3315\n",
      "Epoch: 116, Loss: 0.1005, Train: 0.3170, Val: 0.3316\n",
      "Epoch: 117, Loss: 0.1005, Train: 0.3169, Val: 0.3318\n",
      "Epoch: 118, Loss: 0.1004, Train: 0.3169, Val: 0.3317\n",
      "Epoch: 119, Loss: 0.1004, Train: 0.3168, Val: 0.3315\n",
      "Epoch: 120, Loss: 0.1004, Train: 0.3167, Val: 0.3312\n",
      "Epoch: 121, Loss: 0.1003, Train: 0.3167, Val: 0.3309\n",
      "Epoch: 122, Loss: 0.1003, Train: 0.3166, Val: 0.3307\n",
      "Epoch: 123, Loss: 0.1003, Train: 0.3166, Val: 0.3306\n",
      "Epoch: 124, Loss: 0.1002, Train: 0.3165, Val: 0.3306\n",
      "Epoch: 125, Loss: 0.1002, Train: 0.3165, Val: 0.3307\n",
      "Epoch: 126, Loss: 0.1002, Train: 0.3164, Val: 0.3307\n",
      "Epoch: 127, Loss: 0.1001, Train: 0.3164, Val: 0.3307\n",
      "Epoch: 128, Loss: 0.1001, Train: 0.3163, Val: 0.3305\n",
      "Epoch: 129, Loss: 0.1001, Train: 0.3163, Val: 0.3303\n",
      "Epoch: 130, Loss: 0.1000, Train: 0.3162, Val: 0.3301\n",
      "Epoch: 131, Loss: 0.1000, Train: 0.3162, Val: 0.3299\n",
      "Epoch: 132, Loss: 0.1000, Train: 0.3161, Val: 0.3298\n",
      "Epoch: 133, Loss: 0.0999, Train: 0.3161, Val: 0.3298\n",
      "Epoch: 134, Loss: 0.0999, Train: 0.3160, Val: 0.3298\n",
      "Epoch: 135, Loss: 0.0999, Train: 0.3160, Val: 0.3298\n",
      "Epoch: 136, Loss: 0.0998, Train: 0.3159, Val: 0.3297\n",
      "Epoch: 137, Loss: 0.0998, Train: 0.3159, Val: 0.3296\n",
      "Epoch: 138, Loss: 0.0998, Train: 0.3158, Val: 0.3294\n",
      "Epoch: 139, Loss: 0.0998, Train: 0.3158, Val: 0.3293\n",
      "Epoch: 140, Loss: 0.0997, Train: 0.3157, Val: 0.3291\n",
      "Epoch: 141, Loss: 0.0997, Train: 0.3157, Val: 0.3290\n",
      "Epoch: 142, Loss: 0.0997, Train: 0.3157, Val: 0.3290\n",
      "Epoch: 143, Loss: 0.0996, Train: 0.3156, Val: 0.3290\n",
      "Epoch: 144, Loss: 0.0996, Train: 0.3156, Val: 0.3289\n",
      "Epoch: 145, Loss: 0.0996, Train: 0.3155, Val: 0.3289\n",
      "Epoch: 146, Loss: 0.0996, Train: 0.3155, Val: 0.3287\n",
      "Epoch: 147, Loss: 0.0995, Train: 0.3154, Val: 0.3286\n",
      "Epoch: 148, Loss: 0.0995, Train: 0.3154, Val: 0.3285\n",
      "Epoch: 149, Loss: 0.0995, Train: 0.3154, Val: 0.3284\n",
      "Epoch: 150, Loss: 0.0994, Train: 0.3153, Val: 0.3283\n",
      "Epoch: 151, Loss: 0.0994, Train: 0.3153, Val: 0.3282\n",
      "Epoch: 152, Loss: 0.0994, Train: 0.3152, Val: 0.3282\n",
      "Epoch: 153, Loss: 0.0994, Train: 0.3152, Val: 0.3281\n",
      "Epoch: 154, Loss: 0.0993, Train: 0.3151, Val: 0.3280\n",
      "Epoch: 155, Loss: 0.0993, Train: 0.3151, Val: 0.3279\n",
      "Epoch: 156, Loss: 0.0993, Train: 0.3151, Val: 0.3278\n",
      "Epoch: 157, Loss: 0.0993, Train: 0.3150, Val: 0.3277\n",
      "Epoch: 158, Loss: 0.0992, Train: 0.3150, Val: 0.3276\n",
      "Epoch: 159, Loss: 0.0992, Train: 0.3149, Val: 0.3276\n",
      "Epoch: 160, Loss: 0.0992, Train: 0.3149, Val: 0.3275\n",
      "Epoch: 161, Loss: 0.0992, Train: 0.3149, Val: 0.3275\n",
      "Epoch: 162, Loss: 0.0991, Train: 0.3148, Val: 0.3274\n",
      "Epoch: 163, Loss: 0.0991, Train: 0.3148, Val: 0.3273\n",
      "Epoch: 164, Loss: 0.0991, Train: 0.3147, Val: 0.3272\n",
      "Epoch: 165, Loss: 0.0991, Train: 0.3147, Val: 0.3271\n",
      "Epoch: 166, Loss: 0.0990, Train: 0.3147, Val: 0.3270\n",
      "Epoch: 167, Loss: 0.0990, Train: 0.3146, Val: 0.3269\n",
      "Epoch: 168, Loss: 0.0990, Train: 0.3146, Val: 0.3269\n",
      "Epoch: 169, Loss: 0.0990, Train: 0.3146, Val: 0.3268\n",
      "Epoch: 170, Loss: 0.0989, Train: 0.3145, Val: 0.3267\n",
      "Epoch: 171, Loss: 0.0989, Train: 0.3145, Val: 0.3267\n",
      "Epoch: 172, Loss: 0.0989, Train: 0.3144, Val: 0.3266\n",
      "Epoch: 173, Loss: 0.0989, Train: 0.3144, Val: 0.3265\n",
      "Epoch: 174, Loss: 0.0989, Train: 0.3144, Val: 0.3264\n",
      "Epoch: 175, Loss: 0.0988, Train: 0.3143, Val: 0.3263\n",
      "Epoch: 176, Loss: 0.0988, Train: 0.3143, Val: 0.3263\n",
      "Epoch: 177, Loss: 0.0988, Train: 0.3143, Val: 0.3262\n",
      "Epoch: 178, Loss: 0.0988, Train: 0.3142, Val: 0.3261\n",
      "Epoch: 179, Loss: 0.0987, Train: 0.3142, Val: 0.3261\n",
      "Epoch: 180, Loss: 0.0987, Train: 0.3142, Val: 0.3260\n",
      "Epoch: 181, Loss: 0.0987, Train: 0.3141, Val: 0.3259\n",
      "Epoch: 182, Loss: 0.0987, Train: 0.3141, Val: 0.3258\n",
      "Epoch: 183, Loss: 0.0987, Train: 0.3141, Val: 0.3258\n",
      "Epoch: 184, Loss: 0.0986, Train: 0.3140, Val: 0.3257\n",
      "Epoch: 185, Loss: 0.0986, Train: 0.3140, Val: 0.3256\n",
      "Epoch: 186, Loss: 0.0986, Train: 0.3140, Val: 0.3256\n",
      "Epoch: 187, Loss: 0.0986, Train: 0.3139, Val: 0.3255\n",
      "Epoch: 188, Loss: 0.0986, Train: 0.3139, Val: 0.3254\n",
      "Epoch: 189, Loss: 0.0985, Train: 0.3139, Val: 0.3254\n",
      "Epoch: 190, Loss: 0.0985, Train: 0.3138, Val: 0.3253\n",
      "Epoch: 191, Loss: 0.0985, Train: 0.3138, Val: 0.3252\n",
      "Epoch: 192, Loss: 0.0985, Train: 0.3138, Val: 0.3252\n",
      "Epoch: 193, Loss: 0.0985, Train: 0.3137, Val: 0.3251\n",
      "Epoch: 194, Loss: 0.0984, Train: 0.3137, Val: 0.3250\n",
      "Epoch: 195, Loss: 0.0984, Train: 0.3137, Val: 0.3250\n",
      "Epoch: 196, Loss: 0.0984, Train: 0.3137, Val: 0.3249\n",
      "Epoch: 197, Loss: 0.0984, Train: 0.3136, Val: 0.3248\n",
      "Epoch: 198, Loss: 0.0984, Train: 0.3136, Val: 0.3248\n",
      "Epoch: 199, Loss: 0.0983, Train: 0.3136, Val: 0.3247\n",
      "Epoch: 200, Loss: 0.0983, Train: 0.3135, Val: 0.3247\n",
      "Epoch: 201, Loss: 0.0983, Train: 0.3135, Val: 0.3246\n",
      "Epoch: 202, Loss: 0.0983, Train: 0.3135, Val: 0.3245\n",
      "Epoch: 203, Loss: 0.0983, Train: 0.3134, Val: 0.3245\n",
      "Epoch: 204, Loss: 0.0982, Train: 0.3134, Val: 0.3244\n",
      "Epoch: 205, Loss: 0.0982, Train: 0.3134, Val: 0.3244\n",
      "Epoch: 206, Loss: 0.0982, Train: 0.3134, Val: 0.3243\n",
      "Epoch: 207, Loss: 0.0982, Train: 0.3133, Val: 0.3242\n",
      "Epoch: 208, Loss: 0.0982, Train: 0.3133, Val: 0.3242\n",
      "Epoch: 209, Loss: 0.0982, Train: 0.3133, Val: 0.3241\n",
      "Epoch: 210, Loss: 0.0981, Train: 0.3133, Val: 0.3241\n",
      "Epoch: 211, Loss: 0.0981, Train: 0.3132, Val: 0.3240\n",
      "Epoch: 212, Loss: 0.0981, Train: 0.3132, Val: 0.3240\n",
      "Epoch: 213, Loss: 0.0981, Train: 0.3132, Val: 0.3239\n",
      "Epoch: 214, Loss: 0.0981, Train: 0.3131, Val: 0.3238\n",
      "Epoch: 215, Loss: 0.0981, Train: 0.3131, Val: 0.3238\n",
      "Epoch: 216, Loss: 0.0980, Train: 0.3131, Val: 0.3237\n",
      "Epoch: 217, Loss: 0.0980, Train: 0.3131, Val: 0.3237\n",
      "Epoch: 218, Loss: 0.0980, Train: 0.3130, Val: 0.3236\n",
      "Epoch: 219, Loss: 0.0980, Train: 0.3130, Val: 0.3236\n",
      "Epoch: 220, Loss: 0.0980, Train: 0.3130, Val: 0.3235\n",
      "Epoch: 221, Loss: 0.0980, Train: 0.3130, Val: 0.3235\n",
      "Epoch: 222, Loss: 0.0979, Train: 0.3129, Val: 0.3234\n",
      "Epoch: 223, Loss: 0.0979, Train: 0.3129, Val: 0.3234\n",
      "Epoch: 224, Loss: 0.0979, Train: 0.3129, Val: 0.3233\n",
      "Epoch: 225, Loss: 0.0979, Train: 0.3129, Val: 0.3233\n",
      "Epoch: 226, Loss: 0.0979, Train: 0.3128, Val: 0.3232\n",
      "Epoch: 227, Loss: 0.0979, Train: 0.3128, Val: 0.3232\n",
      "Epoch: 228, Loss: 0.0979, Train: 0.3128, Val: 0.3231\n",
      "Epoch: 229, Loss: 0.0978, Train: 0.3128, Val: 0.3231\n",
      "Epoch: 230, Loss: 0.0978, Train: 0.3128, Val: 0.3231\n",
      "Epoch: 231, Loss: 0.0978, Train: 0.3127, Val: 0.3230\n",
      "Epoch: 232, Loss: 0.0978, Train: 0.3127, Val: 0.3230\n",
      "Epoch: 233, Loss: 0.0978, Train: 0.3127, Val: 0.3229\n",
      "Epoch: 234, Loss: 0.0978, Train: 0.3127, Val: 0.3229\n",
      "Epoch: 235, Loss: 0.0978, Train: 0.3126, Val: 0.3228\n",
      "Epoch: 236, Loss: 0.0977, Train: 0.3126, Val: 0.3228\n",
      "Epoch: 237, Loss: 0.0977, Train: 0.3126, Val: 0.3227\n",
      "Epoch: 238, Loss: 0.0977, Train: 0.3126, Val: 0.3227\n",
      "Epoch: 239, Loss: 0.0977, Train: 0.3126, Val: 0.3227\n",
      "Epoch: 240, Loss: 0.0977, Train: 0.3125, Val: 0.3226\n",
      "Epoch: 241, Loss: 0.0977, Train: 0.3125, Val: 0.3226\n",
      "Epoch: 242, Loss: 0.0977, Train: 0.3125, Val: 0.3225\n",
      "Epoch: 243, Loss: 0.0976, Train: 0.3125, Val: 0.3225\n",
      "Epoch: 244, Loss: 0.0976, Train: 0.3124, Val: 0.3224\n",
      "Epoch: 245, Loss: 0.0976, Train: 0.3124, Val: 0.3224\n",
      "Epoch: 246, Loss: 0.0976, Train: 0.3124, Val: 0.3224\n",
      "Epoch: 247, Loss: 0.0976, Train: 0.3124, Val: 0.3223\n",
      "Epoch: 248, Loss: 0.0976, Train: 0.3124, Val: 0.3223\n",
      "Epoch: 249, Loss: 0.0976, Train: 0.3123, Val: 0.3223\n",
      "Epoch: 250, Loss: 0.0976, Train: 0.3123, Val: 0.3222\n",
      "Epoch: 251, Loss: 0.0975, Train: 0.3123, Val: 0.3222\n",
      "Epoch: 252, Loss: 0.0975, Train: 0.3123, Val: 0.3221\n",
      "Epoch: 253, Loss: 0.0975, Train: 0.3123, Val: 0.3221\n",
      "Epoch: 254, Loss: 0.0975, Train: 0.3122, Val: 0.3221\n",
      "Epoch: 255, Loss: 0.0975, Train: 0.3122, Val: 0.3220\n",
      "Epoch: 256, Loss: 0.0975, Train: 0.3122, Val: 0.3220\n",
      "Epoch: 257, Loss: 0.0975, Train: 0.3122, Val: 0.3220\n",
      "Epoch: 258, Loss: 0.0975, Train: 0.3122, Val: 0.3219\n",
      "Epoch: 259, Loss: 0.0974, Train: 0.3121, Val: 0.3219\n",
      "Epoch: 260, Loss: 0.0974, Train: 0.3121, Val: 0.3219\n",
      "Epoch: 261, Loss: 0.0974, Train: 0.3121, Val: 0.3218\n",
      "Epoch: 262, Loss: 0.0974, Train: 0.3121, Val: 0.3218\n",
      "Epoch: 263, Loss: 0.0974, Train: 0.3121, Val: 0.3218\n",
      "Epoch: 264, Loss: 0.0974, Train: 0.3121, Val: 0.3217\n",
      "Epoch: 265, Loss: 0.0974, Train: 0.3120, Val: 0.3217\n",
      "Epoch: 266, Loss: 0.0974, Train: 0.3120, Val: 0.3217\n",
      "Epoch: 267, Loss: 0.0974, Train: 0.3120, Val: 0.3216\n",
      "Epoch: 268, Loss: 0.0973, Train: 0.3120, Val: 0.3216\n",
      "Epoch: 269, Loss: 0.0973, Train: 0.3120, Val: 0.3216\n",
      "Epoch: 270, Loss: 0.0973, Train: 0.3120, Val: 0.3215\n",
      "Epoch: 271, Loss: 0.0973, Train: 0.3119, Val: 0.3215\n",
      "Epoch: 272, Loss: 0.0973, Train: 0.3119, Val: 0.3215\n",
      "Epoch: 273, Loss: 0.0973, Train: 0.3119, Val: 0.3214\n",
      "Epoch: 274, Loss: 0.0973, Train: 0.3119, Val: 0.3214\n",
      "Epoch: 275, Loss: 0.0973, Train: 0.3119, Val: 0.3214\n",
      "Epoch: 276, Loss: 0.0973, Train: 0.3119, Val: 0.3214\n",
      "Epoch: 277, Loss: 0.0973, Train: 0.3118, Val: 0.3213\n",
      "Epoch: 278, Loss: 0.0972, Train: 0.3118, Val: 0.3213\n",
      "Epoch: 279, Loss: 0.0972, Train: 0.3118, Val: 0.3213\n",
      "Epoch: 280, Loss: 0.0972, Train: 0.3118, Val: 0.3212\n",
      "Epoch: 281, Loss: 0.0972, Train: 0.3118, Val: 0.3212\n",
      "Epoch: 282, Loss: 0.0972, Train: 0.3118, Val: 0.3212\n",
      "Epoch: 283, Loss: 0.0972, Train: 0.3117, Val: 0.3212\n",
      "Epoch: 284, Loss: 0.0972, Train: 0.3117, Val: 0.3211\n",
      "Epoch: 285, Loss: 0.0972, Train: 0.3117, Val: 0.3211\n",
      "Epoch: 286, Loss: 0.0972, Train: 0.3117, Val: 0.3211\n",
      "Epoch: 287, Loss: 0.0972, Train: 0.3117, Val: 0.3211\n",
      "Epoch: 288, Loss: 0.0971, Train: 0.3117, Val: 0.3210\n",
      "Epoch: 289, Loss: 0.0971, Train: 0.3116, Val: 0.3210\n",
      "Epoch: 290, Loss: 0.0971, Train: 0.3116, Val: 0.3210\n",
      "Epoch: 291, Loss: 0.0971, Train: 0.3116, Val: 0.3210\n",
      "Epoch: 292, Loss: 0.0971, Train: 0.3116, Val: 0.3209\n",
      "Epoch: 293, Loss: 0.0971, Train: 0.3116, Val: 0.3209\n",
      "Epoch: 294, Loss: 0.0971, Train: 0.3116, Val: 0.3209\n",
      "Epoch: 295, Loss: 0.0971, Train: 0.3116, Val: 0.3209\n",
      "Epoch: 296, Loss: 0.0971, Train: 0.3115, Val: 0.3208\n",
      "Epoch: 297, Loss: 0.0971, Train: 0.3115, Val: 0.3208\n",
      "Epoch: 298, Loss: 0.0970, Train: 0.3115, Val: 0.3208\n",
      "Epoch: 299, Loss: 0.0970, Train: 0.3115, Val: 0.3208\n",
      "Epoch: 300, Loss: 0.0970, Train: 0.3115, Val: 0.3207\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paso 1: One-Hot Encoding de las columnas categóricas 'region_1', 'partido_1', 'sector_1'\n",
    "one_hot_features = pd.get_dummies(nodos[['region_1', 'partido_1', 'sector_1']])\n",
    "one_hot_tensor = torch.tensor(one_hot_features.values, dtype=torch.float)\n",
    "\n",
    "# Paso 2: Generar embeddings para las biografías usando SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "with torch.no_grad():\n",
    "    bio_embeddings = model.encode(nodos['biografia_1'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "    bio_embeddings = bio_embeddings.cpu()\n",
    "\n",
    "# Paso 3: Concatenar las características (One-Hot + Embeddings)\n",
    "node_features = torch.cat([one_hot_tensor, bio_embeddings], dim=-1)\n",
    "\n",
    "# Crear mapeo de IDs para los parlamentarios\n",
    "unique_parliamentarians = pd.concat([aristas['parliamentarian_1'], aristas['parliamentarian_2']]).unique()\n",
    "parliamentarian_to_index = {name: idx for idx, name in enumerate(unique_parliamentarians)}\n",
    "\n",
    "# Mapear los IDs en las aristas\n",
    "aristas['source'] = aristas['parliamentarian_1'].map(parliamentarian_to_index)\n",
    "aristas['target'] = aristas['parliamentarian_2'].map(parliamentarian_to_index)\n",
    "\n",
    "# Crear el edge_index para el grafo\n",
    "edge_index = torch.tensor([aristas['source'].values, aristas['target'].values], dtype=torch.long)\n",
    "\n",
    "# Usar 'proportion_agreement' como etiquetas\n",
    "edge_label = torch.tensor(aristas['proportion_agreement'].values, dtype=torch.float)\n",
    "\n",
    "# Paso 4: Dividir los datos manualmente usando train_test_split\n",
    "train_edges, temp_edges = train_test_split(aristas, test_size=0.30, random_state=42)\n",
    "val_edges, test_edges = train_test_split(temp_edges, test_size=0.50, random_state=42)\n",
    "\n",
    "# Extraer los edge_index y las etiquetas (valores continuos)\n",
    "train_edge_index = torch.tensor([train_edges['source'].values, train_edges['target'].values], dtype=torch.long)\n",
    "val_edge_index = torch.tensor([val_edges['source'].values, val_edges['target'].values], dtype=torch.long)\n",
    "test_edge_index = torch.tensor([test_edges['source'].values, test_edges['target'].values], dtype=torch.long)\n",
    "\n",
    "train_edge_label = torch.tensor(train_edges['proportion_agreement'].values, dtype=torch.float)\n",
    "val_edge_label = torch.tensor(val_edges['proportion_agreement'].values, dtype=torch.float)\n",
    "test_edge_label = torch.tensor(test_edges['proportion_agreement'].values, dtype=torch.float)\n",
    "\n",
    "# Crear los objetos Data para cada conjunto\n",
    "train_data = Data(x=node_features, edge_index=train_edge_index, edge_label=train_edge_label)\n",
    "val_data = Data(x=node_features, edge_index=val_edge_index, edge_label=val_edge_label)\n",
    "test_data = Data(x=node_features, edge_index=test_edge_index, edge_label=test_edge_label)\n",
    "\n",
    "# Paso 5: Definir el modelo GNN\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(-1, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        row, col = edge_index\n",
    "        z = torch.cat([z[row], z[col]], dim=-1)\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        z = self.encoder(x, edge_index)\n",
    "        return self.decoder(z, edge_index)\n",
    "\n",
    "# Paso 6: Entrenamiento del modelo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Model(hidden_channels=32).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x, train_data.edge_index)  # Se usa edge_index en lugar de edge_label_index\n",
    "    target = train_data.edge_label\n",
    "    loss = F.mse_loss(pred, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    data = data.to(device)\n",
    "    model.eval()\n",
    "    pred = model(data.x, data.edge_index)  # Se usa edge_index en lugar de edge_label_index\n",
    "    target = data.edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)\n",
    "@torch.no_grad()\n",
    "def predict(data):\n",
    "    data = data.to(device)\n",
    "    model.eval()\n",
    "    pred = model(data.x, data.edge_index)  # Predicciones del modelo\n",
    "    target = data.edge_label.float()  # Valores reales\n",
    "    return pred.cpu().numpy(), target.cpu().numpy()  # Devuelve como numpy arrays para facilitar su uso en Pandas\n",
    "\n",
    "# Entrenar el modelo por 300 épocas\n",
    "for epoch in range(1, 301):\n",
    "    train_data = train_data.to(device)\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, Val: {val_rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "datos_completos = {\n",
    "    'nodos': nodos.to_dict(orient='records'),\n",
    "    'aristas': aristas.to_dict(orient='records'),\n",
    "    'parliamentarian_to_index': parliamentarian_to_index,\n",
    "    'index_to_parliamentarian': index_to_parliamentarian,\n",
    "    'embeddings': embeddings.tolist()\n",
    "}\n",
    "\n",
    "# Guardar el diccionario completo en un archivo JSON\n",
    "with open('datos_completos.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(datos_completos, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo JSON con todos los datos\n",
    "def cargar_datos():\n",
    "    with open('datos_completos.json', 'r', encoding='utf-8') as f:\n",
    "        datos_completos = json.load(f)\n",
    "    \n",
    "    # Convertir los datos en sus respectivos formatos\n",
    "    nodos = pd.DataFrame(datos_completos['nodos'])\n",
    "    aristas = pd.DataFrame(datos_completos['aristas'])\n",
    "    parliamentarian_to_index = datos_completos['parliamentarian_to_index']\n",
    "    index_to_parliamentarian = datos_completos['index_to_parliamentarian']\n",
    "    embeddings = torch.tensor(datos_completos['embeddings'])\n",
    "    \n",
    "    return nodos, aristas, parliamentarian_to_index, index_to_parliamentarian, embeddings\n",
    "\n",
    "# Cargar los datos\n",
    "nodos, aristas, parliamentarian_to_index, index_to_parliamentarian, embeddings = cargar_datos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cargando la imagen: cannot identify image file <_io.BytesIO object at 0x000001EC69448EA0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_35348\\2107952269.py\", line 81, in consultar_nodo\n",
      "    img = Image.open(BytesIO(img_data))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py\", line 3498, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000001EC69448EA0>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1968, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_35348\\2107952269.py\", line 98, in consultar_nodo\n",
      "    img_label.config(image='')\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1722, in configure\n",
      "    return self._configure('configure', cnf, kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1712, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "_tkinter.TclError: invalid command name \".!label3\"\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Obtener los embeddings de los nodos después del entrenamiento\n",
    "@torch.no_grad()\n",
    "def obtener_embeddings(data):\n",
    "    data = data.to(device)\n",
    "    model.eval()\n",
    "    embeddings = model.encoder(data.x, data.edge_index)\n",
    "    return embeddings.cpu().numpy()  # Convertir a numpy array para facilitar cálculos de similitud\n",
    "\n",
    "# Obtener los embeddings de los nodos de test\n",
    "embeddings = obtener_embeddings(test_data)\n",
    "similitud = cosine_similarity(embeddings)\n",
    "\n",
    "# Crear un mapeo inverso de índices a nombres de parlamentarios\n",
    "index_to_parliamentarian = {idx: name for name, idx in parliamentarian_to_index.items()}\n",
    "\n",
    "# Crear un mapeo de nombres a índices de parlamentarios (para facilitar la búsqueda)\n",
    "parliamentarian_to_index = {name: idx for idx, name in index_to_parliamentarian.items()}\n",
    "\n",
    "# Función para obtener los nodos más similares por nombre\n",
    "def nodos_mas_parecidos_con_nombres(nodo_idx, top_k=5):\n",
    "    similitudes_nodo = similitud[nodo_idx]\n",
    "    nodos_parecidos = similitudes_nodo.argsort()[::-1][1:top_k+1]  # Obtener los índices de los nodos más parecidos\n",
    "    nombres_parecidos = [index_to_parliamentarian[nodo] for nodo in nodos_parecidos]  # Convertir índices a nombres\n",
    "    return nombres_parecidos, similitudes_nodo[nodos_parecidos]\n",
    "\n",
    "# Función para verificar si hay una arista entre dos nodos y obtener proportion_agreement y sector político del nodo encontrado\n",
    "def obtener_arista_df(df_aristas, nombre_1, nombre_2):\n",
    "    relacion = df_aristas[((df_aristas['parliamentarian_1'] == nombre_1) & (df_aristas['parliamentarian_2'] == nombre_2)) |\n",
    "                          ((df_aristas['parliamentarian_1'] == nombre_2) & (df_aristas['parliamentarian_2'] == nombre_1))]\n",
    "    if not relacion.empty:\n",
    "        # Si existe la relación, devolver True, proportion_agreement, y el sector del nodo encontrado (nombre_2)\n",
    "        proportion_agreement = relacion.iloc[0]['proportion_agreement']\n",
    "        sector_nodo_encontrado = relacion.iloc[0]['sector_2'] if relacion.iloc[0]['parliamentarian_2'] == nombre_2 else relacion.iloc[0]['sector_1']\n",
    "        return True, proportion_agreement, sector_nodo_encontrado\n",
    "    else:\n",
    "        # Si no existe relación, devolver False y None\n",
    "        return False, None, None\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Función para manejar la consulta desde la interfaz gráfica\n",
    "# Función para manejar la consulta desde la interfaz gráfica\n",
    "def consultar_nodo():\n",
    "    nombre_nodo_consulta = combo.get()\n",
    "    if nombre_nodo_consulta in parliamentarian_to_index:\n",
    "        nodo_consulta_idx = parliamentarian_to_index[nombre_nodo_consulta]  # Obtener el índice del nodo consultado\n",
    "        \n",
    "        # Obtener el sector político del nodo consultado\n",
    "        sector_nodo_consulta = aristas.loc[aristas['parliamentarian_1'] == nombre_nodo_consulta, 'sector_1'].values[0]\n",
    "        resultado_label.config(text=f\"Sector político del nodo consultado: {sector_nodo_consulta}\")\n",
    "        \n",
    "        # Buscar los nodos más similares por nombre\n",
    "        nodos_parecidos_nombres, similitudes = nodos_mas_parecidos_con_nombres(nodo_consulta_idx, top_k=5)\n",
    "        \n",
    "        # Limpiar resultados previos\n",
    "        resultados_box.delete(1.0, tk.END)\n",
    "\n",
    "        # Imprimir resultados en la caja de texto\n",
    "        resultados_box.insert(tk.END, f\"Nombres de los nodos más parecidos:\\n\")\n",
    "        for i, nodo in enumerate(nodos_parecidos_nombres):\n",
    "            resultados_box.insert(tk.END, f\"{nodo} (Similitud: {similitudes[i]:.4f})\\n\")\n",
    "        \n",
    "        # Mostrar la imagen del parlamentario consultado\n",
    "        url_imagen = nodos.loc[nodos['parliamentarian_1'] == nombre_nodo_consulta, 'url_imagen_1'].values[0]\n",
    "        try:\n",
    "            response = requests.get(url_imagen)\n",
    "            img_data = response.content\n",
    "            img = Image.open(BytesIO(img_data))\n",
    "            img = img.resize((150, 150))  # Redimensionar la imagen\n",
    "            img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "            # Declarar 'img_label' como global antes de usarla\n",
    "            global img_label\n",
    "            if 'img_label' in globals():\n",
    "                img_label.config(image=img_tk)\n",
    "                img_label.image = img_tk\n",
    "            else:\n",
    "                img_label = tk.Label(root, image=img_tk)\n",
    "                img_label.image = img_tk\n",
    "                img_label.pack(pady=10)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando la imagen: {e}\")\n",
    "            if 'img_label' in globals():\n",
    "                img_label.config(image='')\n",
    "    \n",
    "    else:\n",
    "        resultado_label.config(text=f\"El nodo con nombre {nombre_nodo_consulta} no existe.\")\n",
    "\n",
    "\n",
    "\n",
    "# Lista de nombres de parlamentarios (simulada, debe venir de tu dataframe original)\n",
    "nombres_nodos = list(parliamentarian_to_index.keys())\n",
    "\n",
    "# Crear la ventana principal\n",
    "root = tk.Tk()\n",
    "root.title(\"Consulta de Parlamentarios\")\n",
    "root.geometry(\"500x700\")  # Aumenté el tamaño para incluir la imagen\n",
    "\n",
    "# Etiqueta principal\n",
    "label = tk.Label(root, text=\"Selecciona un parlamentario para consultar\", font=(\"Arial\", 14))\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Crear un menú desplegable (combobox) para seleccionar parlamentarios\n",
    "combo = ttk.Combobox(root, values=nombres_nodos, font=(\"Arial\", 12))\n",
    "combo.pack(pady=10)\n",
    "\n",
    "# Botón para consultar el nodo seleccionado\n",
    "boton = tk.Button(root, text=\"Consultar\", font=(\"Arial\", 12), command=consultar_nodo)\n",
    "boton.pack(pady=10)\n",
    "\n",
    "# Etiqueta donde se mostrará el nodo consultado\n",
    "resultado_label = tk.Label(root, text=\"\", font=(\"Arial\", 12))\n",
    "resultado_label.pack(pady=10)\n",
    "\n",
    "# Caja de texto donde se mostrarán los resultados\n",
    "resultados_box = tk.Text(root, height=10, width=60, font=(\"Arial\", 10))\n",
    "resultados_box.pack(pady=10)\n",
    "\n",
    "# Ejecutar la ventana\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1968, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_35348\\3350612482.py\", line 60, in consultar_nodo\n",
      "    nodos_parecidos_nombres, similitudes = nodos_mas_parecidos_con_nombres(nodo_consulta_idx, top_k=5)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: nodos_mas_parecidos_con_nombres() missing 2 required positional arguments: 'index_to_parliamentarian' and 'nodo_idx'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar los datos desde archivo JSON\n",
    "def cargar_datos():\n",
    "    with open('datos_completos.json', 'r', encoding='utf-8') as f:\n",
    "        datos_completos = json.load(f)\n",
    "    \n",
    "    nodos = pd.DataFrame(datos_completos['nodos'])\n",
    "    aristas = pd.DataFrame(datos_completos['aristas'])\n",
    "    parliamentarian_to_index = datos_completos['parliamentarian_to_index']\n",
    "    embeddings = torch.tensor(datos_completos['embeddings'])\n",
    "    \n",
    "    return nodos, aristas, parliamentarian_to_index, embeddings\n",
    "\n",
    "# Función para obtener los nodos más similares por nombre\n",
    "def nodos_mas_parecidos_con_nombres(similitud, index_to_parliamentarian, nodo_idx, top_k=5):\n",
    "    similitudes_nodo = similitud[nodo_idx]\n",
    "    nodos_parecidos = similitudes_nodo.argsort()[::-1][1:top_k+1]\n",
    "    nombres_parecidos = [index_to_parliamentarian[nodo] for nodo in nodos_parecidos]\n",
    "    return nombres_parecidos, similitudes_nodo[nodos_parecidos]\n",
    "\n",
    "# Verificar arista y obtener detalles\n",
    "def obtener_arista_df(df_aristas, nombre_1, nombre_2):\n",
    "    relacion = df_aristas[((df_aristas['parliamentarian_1'] == nombre_1) & (df_aristas['parliamentarian_2'] == nombre_2)) |\n",
    "                          ((df_aristas['parliamentarian_1'] == nombre_2) & (df_aristas['parliamentarian_2'] == nombre_1))]\n",
    "    if not relacion.empty:\n",
    "        proportion_agreement = relacion.iloc[0]['proportion_agreement']\n",
    "        sector_nodo_encontrado = relacion.iloc[0]['sector_2'] if relacion.iloc[0]['parliamentarian_2'] == nombre_2 else relacion.iloc[0]['sector_1']\n",
    "        return True, proportion_agreement, sector_nodo_encontrado\n",
    "    else:\n",
    "        return False, None, None\n",
    "\n",
    "# Cargar los datos\n",
    "nodos, aristas, parliamentarian_to_index, embeddings = cargar_datos()\n",
    "\n",
    "# Calcular similitud de embeddings\n",
    "similitud = cosine_similarity(embeddings)\n",
    "\n",
    "# Crear un mapeo inverso de índices a nombres de parlamentarios\n",
    "index_to_parliamentarian = {idx: name for name, idx in parliamentarian_to_index.items()}\n",
    "\n",
    "def consultar_nodo():\n",
    "    nombre_nodo_consulta = combo.get()\n",
    "    if nombre_nodo_consulta in parliamentarian_to_index:\n",
    "        nodo_consulta_idx = parliamentarian_to_index[nombre_nodo_consulta]  # Obtener el índice del nodo consultado\n",
    "        \n",
    "        # Obtener el sector político del nodo consultado\n",
    "        sector_nodo_consulta = aristas.loc[aristas['parliamentarian_1'] == nombre_nodo_consulta, 'sector_1'].values[0]\n",
    "        resultado_label.config(text=f\"Sector político del nodo consultado: {sector_nodo_consulta}\")\n",
    "        \n",
    "        # Buscar los nodos más similares por nombre\n",
    "        nodos_parecidos_nombres, similitudes = nodos_mas_parecidos_con_nombres(nodo_consulta_idx, top_k=5)\n",
    "        \n",
    "        # Limpiar resultados previos\n",
    "        resultados_box.delete(1.0, tk.END)\n",
    "\n",
    "        # Imprimir resultados en la caja de texto\n",
    "        resultados_box.insert(tk.END, f\"Nombres de los nodos más parecidos:\\n\")\n",
    "        for i, nodo in enumerate(nodos_parecidos_nombres):\n",
    "            resultados_box.insert(tk.END, f\"{nodo} (Similitud: {similitudes[i]:.4f})\\n\")\n",
    "        \n",
    "        # Mostrar la imagen del parlamentario consultado\n",
    "        url_imagen = nodos.loc[nodos['parliamentarian_1'] == nombre_nodo_consulta, 'url_imagen_1'].values[0]\n",
    "        try:\n",
    "            response = requests.get(url_imagen)\n",
    "            img_data = response.content\n",
    "            img = Image.open(BytesIO(img_data))\n",
    "            img = img.resize((150, 150))  # Redimensionar la imagen\n",
    "            img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "            # Declarar 'img_label' como global antes de usarla\n",
    "            global img_label\n",
    "            if 'img_label' in globals():\n",
    "                img_label.config(image=img_tk)\n",
    "                img_label.image = img_tk\n",
    "            else:\n",
    "                img_label = tk.Label(root, image=img_tk)\n",
    "                img_label.image = img_tk\n",
    "                img_label.pack(pady=10)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando la imagen: {e}\")\n",
    "            if 'img_label' in globals():\n",
    "                img_label.config(image='')\n",
    "    \n",
    "    else:\n",
    "        resultado_label.config(text=f\"El nodo con nombre {nombre_nodo_consulta} no existe.\")\n",
    "\n",
    "# Lista de nombres de parlamentarios (simulada, debe venir de tu dataframe original)\n",
    "nombres_nodos = list(parliamentarian_to_index.keys())\n",
    "\n",
    "# Crear la ventana principal\n",
    "root = tk.Tk()\n",
    "root.title(\"Consulta de Parlamentarios\")\n",
    "root.geometry(\"500x700\")  # Aumenté el tamaño para incluir la imagen\n",
    "\n",
    "# Etiqueta principal\n",
    "label = tk.Label(root, text=\"Selecciona un parlamentario para consultar\", font=(\"Arial\", 14))\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Crear un menú desplegable (combobox) para seleccionar parlamentarios\n",
    "combo = ttk.Combobox(root, values=nombres_nodos, font=(\"Arial\", 12))\n",
    "combo.pack(pady=10)\n",
    "\n",
    "# Botón para consultar el nodo seleccionado\n",
    "boton = tk.Button(root, text=\"Consultar\", font=(\"Arial\", 12), command=consultar_nodo)\n",
    "boton.pack(pady=10)\n",
    "\n",
    "# Etiqueta donde se mostrará el nodo consultado\n",
    "resultado_label = tk.Label(root, text=\"\", font=(\"Arial\", 12))\n",
    "resultado_label.pack(pady=10)\n",
    "\n",
    "# Caja de texto donde se mostrarán los resultados\n",
    "resultados_box = tk.Text(root, height=10, width=60, font=(\"Arial\", 10))\n",
    "resultados_box.pack(pady=10)\n",
    "\n",
    "# Ejecutar la ventana\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1968, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_35348\\496516582.py\", line 87, in consultar_nodo\n",
      "    img_label.config(image=img_tk)\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1722, in configure\n",
      "    return self._configure('configure', cnf, kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1712, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "_tkinter.TclError: invalid command name \".!label3\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar los datos desde archivo JSON\n",
    "def cargar_datos():\n",
    "    with open('datos_completos.json', 'r', encoding='utf-8') as f:\n",
    "        datos_completos = json.load(f)\n",
    "    \n",
    "    nodos = pd.DataFrame(datos_completos['nodos'])\n",
    "    aristas = pd.DataFrame(datos_completos['aristas'])\n",
    "    parliamentarian_to_index = datos_completos['parliamentarian_to_index']\n",
    "    embeddings = torch.tensor(datos_completos['embeddings'])\n",
    "    \n",
    "    return nodos, aristas, parliamentarian_to_index, embeddings\n",
    "\n",
    "# Función para obtener los nodos más similares por nombre\n",
    "def nodos_mas_parecidos_con_nombres(similitud, index_to_parliamentarian, nodo_idx, top_k=5):\n",
    "    similitudes_nodo = similitud[nodo_idx]\n",
    "    nodos_parecidos = similitudes_nodo.argsort()[::-1][1:top_k+1]\n",
    "    nombres_parecidos = [index_to_parliamentarian[nodo] for nodo in nodos_parecidos]\n",
    "    return nombres_parecidos, similitudes_nodo[nodos_parecidos]\n",
    "\n",
    "# Verificar arista y obtener detalles\n",
    "def obtener_arista_df(df_aristas, nombre_1, nombre_2):\n",
    "    relacion = df_aristas[((df_aristas['parliamentarian_1'] == nombre_1) & (df_aristas['parliamentarian_2'] == nombre_2)) |\n",
    "                          ((df_aristas['parliamentarian_1'] == nombre_2) & (df_aristas['parliamentarian_2'] == nombre_1))]\n",
    "    if not relacion.empty:\n",
    "        proportion_agreement = relacion.iloc[0]['proportion_agreement']\n",
    "        sector_nodo_encontrado = relacion.iloc[0]['sector_2'] if relacion.iloc[0]['parliamentarian_2'] == nombre_2 else relacion.iloc[0]['sector_1']\n",
    "        return True, proportion_agreement, sector_nodo_encontrado\n",
    "    else:\n",
    "        return False, None, None\n",
    "\n",
    "# Cargar los datos\n",
    "nodos, aristas, parliamentarian_to_index, embeddings = cargar_datos()\n",
    "\n",
    "# Calcular similitud de embeddings\n",
    "similitud = cosine_similarity(embeddings)\n",
    "\n",
    "# Crear un mapeo inverso de índices a nombres de parlamentarios\n",
    "index_to_parliamentarian = {idx: name for name, idx in parliamentarian_to_index.items()}\n",
    "\n",
    "# Función para manejar la consulta desde la interfaz gráfica\n",
    "def consultar_nodo():\n",
    "    nombre_nodo_consulta = combo.get()\n",
    "    if nombre_nodo_consulta in parliamentarian_to_index:\n",
    "        nodo_consulta_idx = parliamentarian_to_index[nombre_nodo_consulta]  # Obtener el índice del nodo consultado\n",
    "        \n",
    "        # Obtener el sector político del nodo consultado\n",
    "        sector_nodo_consulta = aristas.loc[aristas['parliamentarian_1'] == nombre_nodo_consulta, 'sector_1'].values[0]\n",
    "        resultado_label.config(text=f\"Sector político del nodo consultado: {sector_nodo_consulta}\")\n",
    "        \n",
    "        # Buscar los nodos más similares por nombre\n",
    "        nodos_parecidos_nombres, similitudes = nodos_mas_parecidos_con_nombres(similitud, index_to_parliamentarian, nodo_consulta_idx, top_k=5)\n",
    "        \n",
    "        # Limpiar resultados previos\n",
    "        resultados_box.delete(1.0, tk.END)\n",
    "\n",
    "        # Imprimir resultados en la caja de texto\n",
    "        resultados_box.insert(tk.END, f\"Nombres de los nodos más parecidos:\\n\")\n",
    "        for i, nodo in enumerate(nodos_parecidos_nombres):\n",
    "            resultados_box.insert(tk.END, f\"{nodo} (Similitud: {similitudes[i]:.4f})\\n\")\n",
    "        \n",
    "        # Mostrar la imagen del parlamentario consultado\n",
    "        url_imagen = nodos.loc[nodos['parliamentarian_1'] == nombre_nodo_consulta, 'url_imagen_1'].values[0]\n",
    "        try:\n",
    "            response = requests.get(url_imagen)\n",
    "            response.raise_for_status()  # Asegura que no hay errores en la respuesta\n",
    "            img_data = response.content\n",
    "            img = Image.open(BytesIO(img_data))\n",
    "            img = img.resize((150, 150))  # Redimensionar la imagen\n",
    "            img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "            # Declarar 'img_label' como global antes de usarla\n",
    "            global img_label\n",
    "\n",
    "            # Verificar si 'img_label' ya existe y es un Label válido\n",
    "            if 'img_label' in globals() and isinstance(img_label, tk.Label):\n",
    "                # Si el widget 'img_label' ya existe, actualizar la imagen\n",
    "                img_label.config(image=img_tk)\n",
    "                img_label.image = img_tk\n",
    "            else:\n",
    "                # Si no existe, crear el widget 'Label' con la imagen\n",
    "                img_label = tk.Label(root, image=img_tk)\n",
    "                img_label.image = img_tk\n",
    "                img_label.pack(pady=10)\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error cargando la imagen: {e}\")\n",
    "            # Si ocurre un error, asegurarse de que 'img_label' no tenga una imagen inválida\n",
    "            if 'img_label' in globals() and isinstance(img_label, tk.Label):\n",
    "                img_label.config(image='')\n",
    "    \n",
    "    else:\n",
    "        resultado_label.config(text=f\"El nodo con nombre {nombre_nodo_consulta} no existe.\")\n",
    "\n",
    "# Lista de nombres de parlamentarios (simulada, debe venir de tu dataframe original)\n",
    "nombres_nodos = list(parliamentarian_to_index.keys())\n",
    "\n",
    "# Crear la ventana principal\n",
    "root = tk.Tk()\n",
    "root.title(\"Consulta de Parlamentarios\")\n",
    "root.geometry(\"500x700\")  # Aumenté el tamaño para incluir la imagen\n",
    "\n",
    "# Etiqueta principal\n",
    "label = tk.Label(root, text=\"Selecciona un parlamentario para consultar\", font=(\"Arial\", 14))\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Crear un menú desplegable (combobox) para seleccionar parlamentarios\n",
    "combo = ttk.Combobox(root, values=nombres_nodos, font=(\"Arial\", 12))\n",
    "combo.pack(pady=10)\n",
    "\n",
    "# Botón para consultar el nodo seleccionado\n",
    "boton = tk.Button(root, text=\"Consultar\", font=(\"Arial\", 12), command=consultar_nodo)\n",
    "boton.pack(pady=10)\n",
    "\n",
    "# Etiqueta donde se mostrará el nodo consultado\n",
    "resultado_label = tk.Label(root, text=\"\", font=(\"Arial\", 12))\n",
    "resultado_label.pack(pady=10)\n",
    "\n",
    "# Caja de texto donde se mostrarán los resultados\n",
    "resultados_box = tk.Text(root, height=10, width=60, font=(\"Arial\", 10))\n",
    "resultados_box.pack(pady=10)\n",
    "\n",
    "# Ejecutar la ventana\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cargando la imagen: invalid command name \".!label3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_35348\\3385843083.py\", line 82, in consultar_nodo\n",
      "    img_label.config(image=img_tk)\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1722, in configure\n",
      "    return self._configure('configure', cnf, kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1712, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "_tkinter.TclError: invalid command name \".!label3\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1968, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_35348\\3385843083.py\", line 92, in consultar_nodo\n",
      "    img_label.config(image='')\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1722, in configure\n",
      "    return self._configure('configure', cnf, kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1712, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "_tkinter.TclError: invalid command name \".!label3\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar los datos desde archivo JSON\n",
    "def cargar_datos():\n",
    "    with open('datos_completos.json', 'r', encoding='utf-8') as f:\n",
    "        datos_completos = json.load(f)\n",
    "    \n",
    "    nodos = pd.DataFrame(datos_completos['nodos'])\n",
    "    aristas = pd.DataFrame(datos_completos['aristas'])\n",
    "    parliamentarian_to_index = datos_completos['parliamentarian_to_index']\n",
    "    embeddings = torch.tensor(datos_completos['embeddings'])\n",
    "    \n",
    "    return nodos, aristas, parliamentarian_to_index, embeddings\n",
    "\n",
    "# Función para obtener los nodos más similares por nombre\n",
    "def nodos_mas_parecidos_con_nombres(similitud, index_to_parliamentarian, nodo_idx, top_k=5):\n",
    "    similitudes_nodo = similitud[nodo_idx]\n",
    "    nodos_parecidos = similitudes_nodo.argsort()[::-1][1:top_k+1]\n",
    "    nombres_parecidos = [index_to_parliamentarian[nodo] for nodo in nodos_parecidos]\n",
    "    return nombres_parecidos, similitudes_nodo[nodos_parecidos]\n",
    "\n",
    "# Verificar arista y obtener detalles\n",
    "def obtener_arista_df(df_aristas, nombre_1, nombre_2):\n",
    "    relacion = df_aristas[((df_aristas['parliamentarian_1'] == nombre_1) & (df_aristas['parliamentarian_2'] == nombre_2)) |\n",
    "                          ((df_aristas['parliamentarian_1'] == nombre_2) & (df_aristas['parliamentarian_2'] == nombre_1))]\n",
    "    if not relacion.empty:\n",
    "        proportion_agreement = relacion.iloc[0]['proportion_agreement']\n",
    "        sector_nodo_encontrado = relacion.iloc[0]['sector_2'] if relacion.iloc[0]['parliamentarian_2'] == nombre_2 else relacion.iloc[0]['sector_1']\n",
    "        return True, proportion_agreement, sector_nodo_encontrado\n",
    "    else:\n",
    "        return False, None, None\n",
    "\n",
    "# Cargar los datos\n",
    "nodos, aristas, parliamentarian_to_index, embeddings = cargar_datos()\n",
    "\n",
    "# Calcular similitud de embeddings\n",
    "similitud = cosine_similarity(embeddings)\n",
    "\n",
    "# Crear un mapeo inverso de índices a nombres de parlamentarios\n",
    "index_to_parliamentarian = {idx: name for name, idx in parliamentarian_to_index.items()}\n",
    "\n",
    "def consultar_nodo():\n",
    "    nombre_nodo_consulta = combo.get()\n",
    "    if nombre_nodo_consulta in parliamentarian_to_index:\n",
    "        nodo_consulta_idx = parliamentarian_to_index[nombre_nodo_consulta]  # Obtener el índice del nodo consultado\n",
    "        \n",
    "        # Obtener el sector político del nodo consultado\n",
    "        sector_nodo_consulta = aristas.loc[aristas['parliamentarian_1'] == nombre_nodo_consulta, 'sector_1'].values[0]\n",
    "        resultado_label.config(text=f\"Sector político del nodo consultado: {sector_nodo_consulta}\")\n",
    "        \n",
    "        # Buscar los nodos más similares por nombre\n",
    "        nodos_parecidos_nombres, similitudes = nodos_mas_parecidos_con_nombres(similitud, index_to_parliamentarian, nodo_consulta_idx, top_k=5)\n",
    "        \n",
    "        # Limpiar resultados previos\n",
    "        resultados_box.delete(1.0, tk.END)\n",
    "\n",
    "        # Imprimir resultados en la caja de texto\n",
    "        resultados_box.insert(tk.END, f\"Nombres de los nodos más parecidos:\\n\")\n",
    "        for i, nodo in enumerate(nodos_parecidos_nombres):\n",
    "            resultados_box.insert(tk.END, f\"{nodo} (Similitud: {similitudes[i]:.4f})\\n\")\n",
    "        \n",
    "        # Mostrar la imagen del parlamentario consultado\n",
    "        url_imagen = nodos.loc[nodos['parliamentarian_1'] == nombre_nodo_consulta, 'url_imagen_1'].values[0]\n",
    "        try:\n",
    "            response = requests.get(url_imagen)\n",
    "            img_data = response.content\n",
    "            img = Image.open(BytesIO(img_data))\n",
    "            img = img.resize((150, 150))  # Redimensionar la imagen\n",
    "            img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "            # Declarar 'img_label' como global antes de usarla\n",
    "            global img_label\n",
    "            if 'img_label' in globals():\n",
    "                img_label.config(image=img_tk)\n",
    "                img_label.image = img_tk\n",
    "            else:\n",
    "                img_label = tk.Label(root, image=img_tk)\n",
    "                img_label.image = img_tk\n",
    "                img_label.pack(pady=10)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando la imagen: {e}\")\n",
    "            if 'img_label' in globals():\n",
    "                img_label.config(image='')\n",
    "    \n",
    "    else:\n",
    "        resultado_label.config(text=f\"El nodo con nombre {nombre_nodo_consulta} no existe.\")\n",
    "\n",
    "# Lista de nombres de parlamentarios (simulada, debe venir de tu dataframe original)\n",
    "nombres_nodos = list(parliamentarian_to_index.keys())\n",
    "\n",
    "# Crear la ventana principal\n",
    "root = tk.Tk()\n",
    "root.title(\"Consulta de Parlamentarios\")\n",
    "root.geometry(\"500x700\")  # Aumenté el tamaño para incluir la imagen\n",
    "\n",
    "# Etiqueta principal\n",
    "label = tk.Label(root, text=\"Selecciona un parlamentario para consultar\", font=(\"Arial\", 14))\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Crear un menú desplegable (combobox) para seleccionar parlamentarios\n",
    "combo = ttk.Combobox(root, values=nombres_nodos, font=(\"Arial\", 12))\n",
    "combo.pack(pady=10)\n",
    "\n",
    "# Botón para consultar el nodo seleccionado\n",
    "boton = tk.Button(root, text=\"Consultar\", font=(\"Arial\", 12), command=consultar_nodo)\n",
    "boton.pack(pady=10)\n",
    "\n",
    "# Etiqueta donde se mostrará el nodo consultado\n",
    "resultado_label = tk.Label(root, text=\"\", font=(\"Arial\", 12))\n",
    "resultado_label.pack(pady=10)\n",
    "\n",
    "# Caja de texto donde se mostrarán los resultados\n",
    "resultados_box = tk.Text(root, height=10, width=60, font=(\"Arial\", 10))\n",
    "resultados_box.pack(pady=10)\n",
    "\n",
    "# Ejecutar la ventana\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cargando la imagen: can't invoke \"winfo\" command: application has been destroyed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_35348\\2887229492.py\", line 81, in consultar_nodo\n",
      "    if 'img_label' in globals() and img_label.winfo_exists():\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1140, in winfo_exists\n",
      "    self.tk.call('winfo', 'exists', self._w))\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_tkinter.TclError: can't invoke \"winfo\" command: application has been destroyed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1968, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_35348\\2887229492.py\", line 91, in consultar_nodo\n",
      "    if 'img_label' in globals() and img_label.winfo_exists():\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1140, in winfo_exists\n",
      "    self.tk.call('winfo', 'exists', self._w))\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_tkinter.TclError: can't invoke \"winfo\" command: application has been destroyed\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar los datos desde archivo JSON\n",
    "def cargar_datos():\n",
    "    with open('datos_completos.json', 'r', encoding='utf-8') as f:\n",
    "        datos_completos = json.load(f)\n",
    "    \n",
    "    nodos = pd.DataFrame(datos_completos['nodos'])\n",
    "    aristas = pd.DataFrame(datos_completos['aristas'])\n",
    "    parliamentarian_to_index = datos_completos['parliamentarian_to_index']\n",
    "    embeddings = torch.tensor(datos_completos['embeddings'])\n",
    "    \n",
    "    return nodos, aristas, parliamentarian_to_index, embeddings\n",
    "\n",
    "# Función para obtener los nodos más similares por nombre\n",
    "def nodos_mas_parecidos_con_nombres(similitud, index_to_parliamentarian, nodo_idx, top_k=5):\n",
    "    similitudes_nodo = similitud[nodo_idx]\n",
    "    nodos_parecidos = similitudes_nodo.argsort()[::-1][1:top_k+1]\n",
    "    nombres_parecidos = [index_to_parliamentarian[nodo] for nodo in nodos_parecidos]\n",
    "    return nombres_parecidos, similitudes_nodo[nodos_parecidos]\n",
    "\n",
    "# Verificar arista y obtener detalles\n",
    "def obtener_arista_df(df_aristas, nombre_1, nombre_2):\n",
    "    relacion = df_aristas[((df_aristas['parliamentarian_1'] == nombre_1) & (df_aristas['parliamentarian_2'] == nombre_2)) |\n",
    "                          ((df_aristas['parliamentarian_1'] == nombre_2) & (df_aristas['parliamentarian_2'] == nombre_1))]\n",
    "    if not relacion.empty:\n",
    "        proportion_agreement = relacion.iloc[0]['proportion_agreement']\n",
    "        sector_nodo_encontrado = relacion.iloc[0]['sector_2'] if relacion.iloc[0]['parliamentarian_2'] == nombre_2 else relacion.iloc[0]['sector_1']\n",
    "        return True, proportion_agreement, sector_nodo_encontrado\n",
    "    else:\n",
    "        return False, None, None\n",
    "\n",
    "# Cargar los datos\n",
    "nodos, aristas, parliamentarian_to_index, embeddings = cargar_datos()\n",
    "\n",
    "# Calcular similitud de embeddings\n",
    "similitud = cosine_similarity(embeddings)\n",
    "\n",
    "# Crear un mapeo inverso de índices a nombres de parlamentarios\n",
    "index_to_parliamentarian = {idx: name for name, idx in parliamentarian_to_index.items()}\n",
    "\n",
    "def consultar_nodo():\n",
    "    nombre_nodo_consulta = combo.get()\n",
    "    if nombre_nodo_consulta in parliamentarian_to_index:\n",
    "        nodo_consulta_idx = parliamentarian_to_index[nombre_nodo_consulta]  # Obtener el índice del nodo consultado\n",
    "        \n",
    "        # Obtener el sector político del nodo consultado\n",
    "        sector_nodo_consulta = aristas.loc[aristas['parliamentarian_1'] == nombre_nodo_consulta, 'sector_1'].values[0]\n",
    "        resultado_label.config(text=f\"Sector político del nodo consultado: {sector_nodo_consulta}\")\n",
    "        \n",
    "        # Buscar los nodos más similares por nombre\n",
    "        nodos_parecidos_nombres, similitudes = nodos_mas_parecidos_con_nombres(similitud, index_to_parliamentarian, nodo_consulta_idx, top_k=5)\n",
    "        \n",
    "        # Limpiar resultados previos\n",
    "        resultados_box.delete(1.0, tk.END)\n",
    "\n",
    "        # Imprimir resultados en la caja de texto\n",
    "        resultados_box.insert(tk.END, f\"Nombres de los nodos más parecidos:\\n\")\n",
    "        for i, nodo in enumerate(nodos_parecidos_nombres):\n",
    "            resultados_box.insert(tk.END, f\"{nodo} (Similitud: {similitudes[i]:.4f})\\n\")\n",
    "        \n",
    "        # Mostrar la imagen del parlamentario consultado\n",
    "        url_imagen = nodos.loc[nodos['parliamentarian_1'] == nombre_nodo_consulta, 'url_imagen_1'].values[0]\n",
    "        try:\n",
    "            response = requests.get(url_imagen)\n",
    "            img_data = response.content\n",
    "            img = Image.open(BytesIO(img_data))\n",
    "            img = img.resize((150, 150))  # Redimensionar la imagen\n",
    "            img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "            # Declarar 'img_label' como global antes de usarla\n",
    "            global img_label\n",
    "            if 'img_label' in globals() and img_label.winfo_exists():\n",
    "                img_label.config(image=img_tk)\n",
    "                img_label.image = img_tk\n",
    "            else:\n",
    "                img_label = tk.Label(root, image=img_tk)\n",
    "                img_label.image = img_tk\n",
    "                img_label.pack(pady=10)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando la imagen: {e}\")\n",
    "            if 'img_label' in globals() and img_label.winfo_exists():\n",
    "                img_label.config(image='')\n",
    "    \n",
    "    else:\n",
    "        resultado_label.config(text=f\"El nodo con nombre {nombre_nodo_consulta} no existe.\")\n",
    "\n",
    "# Lista de nombres de parlamentarios (simulada, debe venir de tu dataframe original)\n",
    "nombres_nodos = list(parliamentarian_to_index.keys())\n",
    "\n",
    "# Crear la ventana principal\n",
    "root = tk.Tk()\n",
    "root.title(\"Consulta de Parlamentarios\")\n",
    "root.geometry(\"500x700\")  # Aumenté el tamaño para incluir la imagen\n",
    "\n",
    "# Etiqueta principal\n",
    "label = tk.Label(root, text=\"Selecciona un parlamentario para consultar\", font=(\"Arial\", 14))\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Crear un menú desplegable (combobox) para seleccionar parlamentarios\n",
    "combo = ttk.Combobox(root, values=nombres_nodos, font=(\"Arial\", 12))\n",
    "combo.pack(pady=10)\n",
    "\n",
    "# Botón para consultar el nodo seleccionado\n",
    "boton = tk.Button(root, text=\"Consultar\", font=(\"Arial\", 12), command=consultar_nodo)\n",
    "boton.pack(pady=10)\n",
    "\n",
    "# Etiqueta donde se mostrará el nodo consultado\n",
    "resultado_label = tk.Label(root, text=\"\", font=(\"Arial\", 12))\n",
    "resultado_label.pack(pady=10)\n",
    "\n",
    "# Caja de texto donde se mostrarán los resultados\n",
    "resultados_box = tk.Text(root, height=10, width=60, font=(\"Arial\", 10))\n",
    "resultados_box.pack(pady=10)\n",
    "\n",
    "# Ejecutar la ventana\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
